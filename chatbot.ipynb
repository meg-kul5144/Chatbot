{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26516e24-418b-44c1-99b7-4a405f1f0077",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "#nltk.download('punkt_tab')\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import warnings\n",
    "#!pip install tensorflow\n",
    "import tensorflow.keras.models\n",
    "from nltk.corpus import stopwords\n",
    "#nltk.download('stopwords')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#nltk.download('wordnet')\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, Dense, Activation, Input, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from textattack.augmentation import EasyDataAugmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d78e0b03-e0af-4226-ad2b-693e4683c843",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    path = 'C:/Users/61450/Desktop/New folder/Chatbot/intents.json'\n",
    "except FileNotFoundError as e: \n",
    "    print(f\"Error: {e}\") \n",
    "    \n",
    "with open(path, 'r') as file:\n",
    "   uni_dt = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2a2d6e2-5e31-4e5a-a263-7ffe24edf08d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['greeting',\n",
       " 'goodbye',\n",
       " 'creator',\n",
       " 'name',\n",
       " 'hours',\n",
       " 'number',\n",
       " 'course',\n",
       " 'fees',\n",
       " 'location',\n",
       " 'hostel',\n",
       " 'event',\n",
       " 'document',\n",
       " 'floors',\n",
       " 'syllabus',\n",
       " 'library',\n",
       " 'infrastructure',\n",
       " 'canteen',\n",
       " 'menu',\n",
       " 'placement',\n",
       " 'ithod',\n",
       " 'computerhod',\n",
       " 'extchod',\n",
       " 'principal',\n",
       " 'sem',\n",
       " 'admission',\n",
       " 'scholarship',\n",
       " 'facilities',\n",
       " 'college intake',\n",
       " 'uniform',\n",
       " 'committee',\n",
       " 'random',\n",
       " 'swear',\n",
       " 'vacation',\n",
       " 'sports',\n",
       " 'salutaion',\n",
       " 'task',\n",
       " 'ragging',\n",
       " 'hod',\n",
       " 'Mess Timetable']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[uni_dt['intents'][i]['intent'] for i in range(len(uni_dt['intents']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fe2a36a-45dd-4581-afe1-24f2eab25226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'intent': 'greeting',\n",
       "  'text': ['Hi',\n",
       "   'How are you?',\n",
       "   'Is anyone there?',\n",
       "   'Hello',\n",
       "   'Good day',\n",
       "   \"What's up\",\n",
       "   'how are ya',\n",
       "   'heyy',\n",
       "   'whatsup',\n",
       "   '??? ??? ??'],\n",
       "  'responses': ['Hello!',\n",
       "   'Good to see you again!',\n",
       "   'Hi there, how can I help?'],\n",
       "  'extension': {'function': '', 'entities': False, 'responses': []},\n",
       "  'context': {'in': '', 'out': 'GreetingUserRequest', 'clear': False},\n",
       "  'entityType': 'NA',\n",
       "  'entities': []},\n",
       " {'intent': 'goodbye',\n",
       "  'text': ['cya',\n",
       "   'see you',\n",
       "   'bye bye',\n",
       "   'See you later',\n",
       "   'Goodbye',\n",
       "   'I am Leaving',\n",
       "   'Bye',\n",
       "   'Have a Good day',\n",
       "   'talk to you later',\n",
       "   'ttyl',\n",
       "   'i got to go',\n",
       "   'gtg'],\n",
       "  'responses': ['Sad to see you go :(',\n",
       "   'Talk to you later',\n",
       "   'Goodbye!',\n",
       "   'Come back soon'],\n",
       "  'extension': {'function': '', 'entities': False, 'responses': []},\n",
       "  'context': {'in': '', 'out': 'LeavingUserRequest', 'clear': False},\n",
       "  'entityType': 'NA',\n",
       "  'entities': []}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The loaded data has information about university queries. The file contains a list of intents with tags, text(user input), \n",
    "# responses, extension, context, entity type and entities. The data is organized as a nested dictionary where 'intents' is the main key.\n",
    "# Each dictionary value is also a dictionary where the main keys are 'intent', 'text' and 'responses'.\n",
    "\n",
    "uni_dt['intents'][0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b2af3af-8325-4d5a-ab03-6b1338bcf03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install textattack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8cee067e-1f49-4abb-b3d6-5317be4c701f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\61450\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#The tags and user input text are reorganized as dataframe for clear representation of tag/intent for each user input.\n",
    "\n",
    "eda_aug = EasyDataAugmenter()\n",
    "\n",
    "user_in = []\n",
    "tag_in = []\n",
    "for i in range(len(uni_dt['intents'])):\n",
    "    for k in uni_dt['intents'][i]['text']:\n",
    "        user_in.append([k])\n",
    "        user_in.append(eda_aug.augment(k))\n",
    "        l = len(eda_aug.augment(k))\n",
    "        tag_in.append(uni_dt['intents'][i]['intent'])\n",
    "        for x in range(l):\n",
    "            tag_in.append(uni_dt['intents'][i]['intent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "15a1fbc0-72fc-42fc-9d9e-02f19334ea8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1955"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input = [x for m in user_in for x in m]\n",
    "len(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a241b17e-aac6-4bed-a7dc-e0f927e90319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1955"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tag_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1ced3430-27b7-4745-8f7d-a158e6ebef4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tags</th>\n",
       "      <th>user_input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greeting</td>\n",
       "      <td>Hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>greeting</td>\n",
       "      <td>Hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>greeting</td>\n",
       "      <td>hello Hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>greeting</td>\n",
       "      <td>how-do-you-do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>greeting</td>\n",
       "      <td>How are you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950</th>\n",
       "      <td>Mess Timetable</td>\n",
       "      <td>Academic Calander</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>Mess Timetable</td>\n",
       "      <td>Calander Academic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1952</th>\n",
       "      <td>Mess Timetable</td>\n",
       "      <td>donnish Calander</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1953</th>\n",
       "      <td>Mess Timetable</td>\n",
       "      <td>Academic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954</th>\n",
       "      <td>Mess Timetable</td>\n",
       "      <td>pedantic Academic Calander</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1955 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                tags                  user_input\n",
       "0           greeting                          Hi\n",
       "1           greeting                          Hi\n",
       "2           greeting                    hello Hi\n",
       "3           greeting               how-do-you-do\n",
       "4           greeting                How are you?\n",
       "...              ...                         ...\n",
       "1950  Mess Timetable           Academic Calander\n",
       "1951  Mess Timetable           Calander Academic\n",
       "1952  Mess Timetable            donnish Calander\n",
       "1953  Mess Timetable                   Academic \n",
       "1954  Mess Timetable  pedantic Academic Calander\n",
       "\n",
       "[1955 rows x 2 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_data_in = pd.DataFrame({'tags':tag_in, 'user_input':user_input})\n",
    "uni_data_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1a51b54d-8ccb-4e53-924f-ca0c23d25df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tags</th>\n",
       "      <th>responses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greeting</td>\n",
       "      <td>Hello!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>greeting</td>\n",
       "      <td>Good to see you again!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>greeting</td>\n",
       "      <td>Hi there, how can I help?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>goodbye</td>\n",
       "      <td>Sad to see you go :(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>goodbye</td>\n",
       "      <td>Talk to you later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>goodbye</td>\n",
       "      <td>Goodbye!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>goodbye</td>\n",
       "      <td>Come back soon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>creator</td>\n",
       "      <td>College students</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>name</td>\n",
       "      <td>You can call me Mind Reader.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>name</td>\n",
       "      <td>I'm Mind Reader</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>name</td>\n",
       "      <td>I am a Chatbot.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>name</td>\n",
       "      <td>I am your helper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hours</td>\n",
       "      <td>College is open 8am-5pm Monday-Saturday!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>number</td>\n",
       "      <td>You can contact at: NUMBER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>course</td>\n",
       "      <td>Our university offers Information Technology, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>fees</td>\n",
       "      <td>For Fee detail visit &lt;a target=\"_blank\" href=\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>location</td>\n",
       "      <td>&lt;a target=\"_blank\" href=\"ADD YOU GOOGLE MAP LI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>hostel</td>\n",
       "      <td>For hostel detail visit &lt;a target=\"_blank\" hre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>event</td>\n",
       "      <td>For event detail visit &lt;a target=\"_blank\" href...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>document</td>\n",
       "      <td>To know more about document required visit &lt;a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>floors</td>\n",
       "      <td>My College has total 2 floors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>syllabus</td>\n",
       "      <td>Timetable provide direct to the students OR To...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>library</td>\n",
       "      <td>There is one huge and spacious library.timings...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>infrastructure</td>\n",
       "      <td>Our University has Excellent Infrastructure. C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>canteen</td>\n",
       "      <td>Our university has canteen with variety of foo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>menu</td>\n",
       "      <td>we serve Franky, Locho, Alu-puri, Kachori, Kha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>placement</td>\n",
       "      <td>To know about placement visit &lt;a target=\"_blan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ithod</td>\n",
       "      <td>All engineering departments have only one hod ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>computerhod</td>\n",
       "      <td>All engineering departments have only one hod ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>extchod</td>\n",
       "      <td>Different school wise hod are different.So be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>principal</td>\n",
       "      <td>XYZ is college principal and if you need any h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>sem</td>\n",
       "      <td>Here is the Academic Calendar  &lt;a target=\"_bla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>admission</td>\n",
       "      <td>Application can also be submitted online throu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>scholarship</td>\n",
       "      <td>Many government scholarships are supported by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>facilities</td>\n",
       "      <td>Our university's Engineering department provid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>college intake</td>\n",
       "      <td>For IT, Computer and extc 60 per branch and se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>uniform</td>\n",
       "      <td>ENTER YOUR OWN UNIVERSITY UNIFORM CIRCULER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>committee</td>\n",
       "      <td>For the various committe in college contact th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>random</td>\n",
       "      <td>I am not program for this, please ask appropri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>swear</td>\n",
       "      <td>please use appropriate language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>swear</td>\n",
       "      <td>Maintaining decency would be appreciated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>vacation</td>\n",
       "      <td>Academic calender is given to you by your clas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>sports</td>\n",
       "      <td>Our university encourages all-round developmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>salutaion</td>\n",
       "      <td>I am glad I helped you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>salutaion</td>\n",
       "      <td>welcome, anything else i can assist you with?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>task</td>\n",
       "      <td>I can answer to low-intermediate questions reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>task</td>\n",
       "      <td>You can ask me questions regarding college, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>ragging</td>\n",
       "      <td>We are Proud to tell you that our college prov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>hod</td>\n",
       "      <td>HODs differ for each branch, please be more sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Mess Timetable</td>\n",
       "      <td>Timetable Link visit &lt;a target=\"_blank\" href=\"...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tags                                          responses\n",
       "0         greeting                                             Hello!\n",
       "1         greeting                             Good to see you again!\n",
       "2         greeting                          Hi there, how can I help?\n",
       "3          goodbye                               Sad to see you go :(\n",
       "4          goodbye                                  Talk to you later\n",
       "5          goodbye                                           Goodbye!\n",
       "6          goodbye                                     Come back soon\n",
       "7          creator                                   College students\n",
       "8             name                       You can call me Mind Reader.\n",
       "9             name                                    I'm Mind Reader\n",
       "10            name                                    I am a Chatbot.\n",
       "11            name                                   I am your helper\n",
       "12           hours           College is open 8am-5pm Monday-Saturday!\n",
       "13          number                         You can contact at: NUMBER\n",
       "14          course  Our university offers Information Technology, ...\n",
       "15            fees  For Fee detail visit <a target=\"_blank\" href=\"...\n",
       "16        location  <a target=\"_blank\" href=\"ADD YOU GOOGLE MAP LI...\n",
       "17          hostel  For hostel detail visit <a target=\"_blank\" hre...\n",
       "18           event  For event detail visit <a target=\"_blank\" href...\n",
       "19        document  To know more about document required visit <a ...\n",
       "20          floors                     My College has total 2 floors \n",
       "21        syllabus  Timetable provide direct to the students OR To...\n",
       "22         library  There is one huge and spacious library.timings...\n",
       "23  infrastructure  Our University has Excellent Infrastructure. C...\n",
       "24         canteen  Our university has canteen with variety of foo...\n",
       "25            menu  we serve Franky, Locho, Alu-puri, Kachori, Kha...\n",
       "26       placement  To know about placement visit <a target=\"_blan...\n",
       "27           ithod  All engineering departments have only one hod ...\n",
       "28     computerhod  All engineering departments have only one hod ...\n",
       "29         extchod  Different school wise hod are different.So be ...\n",
       "30       principal  XYZ is college principal and if you need any h...\n",
       "31             sem  Here is the Academic Calendar  <a target=\"_bla...\n",
       "32       admission  Application can also be submitted online throu...\n",
       "33     scholarship  Many government scholarships are supported by ...\n",
       "34      facilities  Our university's Engineering department provid...\n",
       "35  college intake  For IT, Computer and extc 60 per branch and se...\n",
       "36         uniform         ENTER YOUR OWN UNIVERSITY UNIFORM CIRCULER\n",
       "37       committee  For the various committe in college contact th...\n",
       "38          random  I am not program for this, please ask appropri...\n",
       "39           swear                    please use appropriate language\n",
       "40           swear           Maintaining decency would be appreciated\n",
       "41        vacation  Academic calender is given to you by your clas...\n",
       "42          sports  Our university encourages all-round developmen...\n",
       "43       salutaion                             I am glad I helped you\n",
       "44       salutaion      welcome, anything else i can assist you with?\n",
       "45            task  I can answer to low-intermediate questions reg...\n",
       "46            task  You can ask me questions regarding college, an...\n",
       "47         ragging  We are Proud to tell you that our college prov...\n",
       "48             hod  HODs differ for each branch, please be more sp...\n",
       "49  Mess Timetable  Timetable Link visit <a target=\"_blank\" href=\"..."
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The responses and corresponding tags are also reorganized as dataframe for clear representation of tag/intent for each chatbot response.\n",
    "\n",
    "tag_out = []\n",
    "resp = []\n",
    "for i in range(len(uni_dt['intents'])):\n",
    "    for k in uni_dt['intents'][i]['responses']:\n",
    "        resp.append(k)\n",
    "        tag_out.append(uni_dt['intents'][i]['intent'])\n",
    "\n",
    "uni_data_out = pd.DataFrame({'tags':tag_out, 'responses':resp})\n",
    "uni_data_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5b6b56f2-8434-44ce-b80e-672f0e2726bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function is created for preprocessing user text. Stop words have not been excluded as the user content has very short messages with commonly used\n",
    "# words. Removal of any stopword may remove important text from input patterns. Each user text is converted to lower case. Punctuation marks are removed \n",
    "# and the text is subjected to lemmatization for extraction of correct root words.\n",
    "\n",
    "def preprocess(line, remove_stopwords):\n",
    "    line = line.lower()\n",
    "    line = re.sub(r'[^\\w\\s]', ' ',line)\n",
    "    line = line.split()\n",
    "    if remove_stopwords:\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        line = [word for word in line if word not in stop_words]\n",
    "    word_lem = WordNetLemmatizer()\n",
    "    line = [word_lem.lemmatize(i) for i in line]\n",
    "    line = ' '.join(line)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "90b15982-aef8-432d-9778-0cc3a2d4fcab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15, 15, 15, ...,  0,  0,  0])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The tags are the labelled responses and are encoded into integer labels for training the neural network model.\n",
    "\n",
    "label_en = LabelEncoder()\n",
    "labels = label_en.fit_transform(uni_data_in['tags'])\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "869f945e-08bf-48b0-8d79-2003f88d34eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The user input corpus is subjected to preprocessing. The preprocessed text is tokenized to extract a list of unique words\n",
    "# and the size of vocabulary.\n",
    "\n",
    "word_set = []\n",
    "user_sentences = []\n",
    "for sentence in uni_data_in['user_input']:\n",
    "    sent = preprocess(sentence, remove_stopwords=True)\n",
    "    word = word_tokenize(sent)\n",
    "    user_sentences.append(sent)\n",
    "    word_set.append(word)\n",
    "\n",
    "vocab = [m for s in word_set for m in s]\n",
    "vocab = set(vocab)\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a1169282-330c-4f6c-9983-b99a97525359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tags</th>\n",
       "      <th>user_input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>hello hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950</th>\n",
       "      <td>0</td>\n",
       "      <td>academic calander</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>0</td>\n",
       "      <td>calander academic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1952</th>\n",
       "      <td>0</td>\n",
       "      <td>donnish calander</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1953</th>\n",
       "      <td>0</td>\n",
       "      <td>academic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954</th>\n",
       "      <td>0</td>\n",
       "      <td>pedantic academic calander</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1955 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      tags                  user_input\n",
       "0       15                          hi\n",
       "1       15                          hi\n",
       "2       15                    hello hi\n",
       "3       15                            \n",
       "4       15                            \n",
       "...    ...                         ...\n",
       "1950     0           academic calander\n",
       "1951     0           calander academic\n",
       "1952     0            donnish calander\n",
       "1953     0                    academic\n",
       "1954     0  pedantic academic calander\n",
       "\n",
       "[1955 rows x 2 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input data is clean user input and output is the integer label of the corresponding tag.\n",
    "\n",
    "proc_data_in = pd.DataFrame({'tags':labels, 'user_input':user_sentences})\n",
    "proc_data_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "bf4bcf40-db81-4d75-87eb-c750483da99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The tokenizer function is used to convert the input corpus into sequence vectors.\n",
    "\n",
    "tokens = Tokenizer(num_words=vocab_size)\n",
    "tokens.fit_on_texts(proc_data_in['user_input'])\n",
    "encoded_text = tokens.texts_to_sequences(proc_data_in['user_input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "911dfb2b-e95c-4e1a-b6f1-48df572ebe9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The maximumm length of a user input message is extracted to create sequence vectors of uniform lengths\n",
    "\n",
    "max_length = 0\n",
    "for sentence in user_sentences:\n",
    "    if(max_length < len(sentence.split())):\n",
    "        max_length = len(sentence.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f6bb07ea-9408-41f3-9fd2-93ab35a22ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[164,   0,   0, ...,   0,   0,   0],\n",
       "       [164,   0,   0, ...,   0,   0,   0],\n",
       "       [165, 164,   0, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [565, 221,   0, ...,   0,   0,   0],\n",
       "       [220,   0,   0, ...,   0,   0,   0],\n",
       "       [220, 221,   0, ...,   0,   0,   0]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The sequence vectors are padded to the maximum length.\n",
    "\n",
    "padded_data = pad_sequences(encoded_text, maxlen=max_length, padding='post', value=0)\n",
    "padded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a07a082f-b88d-4ec9-ae48-6f726823b364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference used for model building: https://www.kaggle.com/code/uzzivirus/simple-chatbot-using-neural-networks.\n",
    "# The neural network model has an input of length equal to maximum length. \n",
    "# First layer is the embedding layer followed by 3 dense layers.\n",
    "# The ouput layer has length equal to the number of unique tags. The activation function used is 'Relu' and 'softmax' is used\n",
    "# for multi class classfication.\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(max_length,)))\n",
    "model.add(Embedding(input_dim=vocab_size,output_dim=8, input_length=(max_length,)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units= 64, activation='relu'))\n",
    "model.add(Dense(units= 64, activation='relu'))\n",
    "model.add(Dense(units= len(set(labels)), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a7ceb493-7f25-4585-8957-b8238215db11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The optizer used is adam optimiser. Sparse categorical cross entropy is used due to multi class \n",
    "# classification and also because the targets are labelled as integers. \n",
    "\n",
    "model.compile(loss = \"sparse_categorical_crossentropy\", optimizer ='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2ae921c1-2c50-43f6-bf60-f63968cb9ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.0522 - loss: 3.6395 - val_accuracy: 0.0000e+00 - val_loss: 4.4999\n",
      "Epoch 2/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0875 - loss: 3.3761 - val_accuracy: 0.0000e+00 - val_loss: 6.5425\n",
      "Epoch 3/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2362 - loss: 3.0279 - val_accuracy: 0.0000e+00 - val_loss: 7.3006\n",
      "Epoch 4/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3371 - loss: 2.4216 - val_accuracy: 0.0000e+00 - val_loss: 9.0838\n",
      "Epoch 5/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4833 - loss: 1.9421 - val_accuracy: 0.0000e+00 - val_loss: 11.3516\n",
      "Epoch 6/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6031 - loss: 1.5058 - val_accuracy: 0.0000e+00 - val_loss: 13.1706\n",
      "Epoch 7/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7188 - loss: 1.1769 - val_accuracy: 0.0000e+00 - val_loss: 15.0226\n",
      "Epoch 8/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7921 - loss: 0.8929 - val_accuracy: 0.0000e+00 - val_loss: 16.0347\n",
      "Epoch 9/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8484 - loss: 0.7069 - val_accuracy: 0.0000e+00 - val_loss: 16.9614\n",
      "Epoch 10/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8739 - loss: 0.6102 - val_accuracy: 0.0204 - val_loss: 17.9142\n",
      "Epoch 11/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8773 - loss: 0.5672 - val_accuracy: 0.0306 - val_loss: 18.6734\n",
      "Epoch 12/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9083 - loss: 0.4713 - val_accuracy: 0.0306 - val_loss: 19.1494\n",
      "Epoch 13/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9138 - loss: 0.4517 - val_accuracy: 0.0306 - val_loss: 19.6637\n",
      "Epoch 14/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9216 - loss: 0.3983 - val_accuracy: 0.0306 - val_loss: 19.9799\n",
      "Epoch 15/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9220 - loss: 0.3508 - val_accuracy: 0.0306 - val_loss: 20.1307\n",
      "Epoch 16/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9371 - loss: 0.2770 - val_accuracy: 0.0357 - val_loss: 20.1854\n",
      "Epoch 17/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9327 - loss: 0.2802 - val_accuracy: 0.0357 - val_loss: 20.2417\n",
      "Epoch 18/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9436 - loss: 0.2590 - val_accuracy: 0.0357 - val_loss: 20.2393\n",
      "Epoch 19/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9325 - loss: 0.2633 - val_accuracy: 0.0357 - val_loss: 20.6605\n",
      "Epoch 20/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9290 - loss: 0.2798 - val_accuracy: 0.0357 - val_loss: 20.8223\n",
      "Epoch 21/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9409 - loss: 0.2107 - val_accuracy: 0.0357 - val_loss: 20.8747\n",
      "Epoch 22/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9409 - loss: 0.2478 - val_accuracy: 0.0357 - val_loss: 20.8846\n",
      "Epoch 23/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9367 - loss: 0.2378 - val_accuracy: 0.0357 - val_loss: 21.2005\n",
      "Epoch 24/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9356 - loss: 0.2405 - val_accuracy: 0.0357 - val_loss: 21.2211\n",
      "Epoch 25/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9478 - loss: 0.1972 - val_accuracy: 0.0357 - val_loss: 21.4850\n",
      "Epoch 26/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9368 - loss: 0.2230 - val_accuracy: 0.0408 - val_loss: 21.2759\n",
      "Epoch 27/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9425 - loss: 0.1946 - val_accuracy: 0.0357 - val_loss: 21.3227\n",
      "Epoch 28/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9429 - loss: 0.1940 - val_accuracy: 0.0357 - val_loss: 21.4780\n",
      "Epoch 29/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9382 - loss: 0.2316 - val_accuracy: 0.0357 - val_loss: 21.3429\n",
      "Epoch 30/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9317 - loss: 0.2053 - val_accuracy: 0.0357 - val_loss: 21.5122\n",
      "Epoch 31/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9348 - loss: 0.2011 - val_accuracy: 0.0357 - val_loss: 21.5941\n",
      "Epoch 32/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9405 - loss: 0.1919 - val_accuracy: 0.0408 - val_loss: 21.4768\n",
      "Epoch 33/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9394 - loss: 0.2125 - val_accuracy: 0.0357 - val_loss: 21.4396\n",
      "Epoch 34/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9433 - loss: 0.2053 - val_accuracy: 0.0408 - val_loss: 21.2148\n",
      "Epoch 35/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9296 - loss: 0.2180 - val_accuracy: 0.0510 - val_loss: 21.3890\n",
      "Epoch 36/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9422 - loss: 0.1765 - val_accuracy: 0.0357 - val_loss: 21.3392\n",
      "Epoch 37/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9447 - loss: 0.1800 - val_accuracy: 0.0357 - val_loss: 21.3371\n",
      "Epoch 38/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9440 - loss: 0.1834 - val_accuracy: 0.0408 - val_loss: 21.4776\n",
      "Epoch 39/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9412 - loss: 0.1982 - val_accuracy: 0.0357 - val_loss: 21.1003\n",
      "Epoch 40/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9275 - loss: 0.2238 - val_accuracy: 0.0408 - val_loss: 21.3994\n",
      "Epoch 41/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9501 - loss: 0.1567 - val_accuracy: 0.0510 - val_loss: 21.3540\n",
      "Epoch 42/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9298 - loss: 0.2211 - val_accuracy: 0.0408 - val_loss: 21.2280\n",
      "Epoch 43/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9431 - loss: 0.1841 - val_accuracy: 0.0408 - val_loss: 21.1506\n",
      "Epoch 44/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9356 - loss: 0.1871 - val_accuracy: 0.0357 - val_loss: 21.5840\n",
      "Epoch 45/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9416 - loss: 0.1848 - val_accuracy: 0.0357 - val_loss: 21.2472\n",
      "Epoch 46/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9415 - loss: 0.1785 - val_accuracy: 0.0459 - val_loss: 21.3414\n",
      "Epoch 47/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9515 - loss: 0.1637 - val_accuracy: 0.0510 - val_loss: 21.2416\n",
      "Epoch 48/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9384 - loss: 0.1839 - val_accuracy: 0.0459 - val_loss: 21.2139\n",
      "Epoch 49/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9482 - loss: 0.1739 - val_accuracy: 0.0357 - val_loss: 21.0819\n",
      "Epoch 50/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9389 - loss: 0.1796 - val_accuracy: 0.0408 - val_loss: 21.0274\n",
      "Epoch 51/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9398 - loss: 0.1848 - val_accuracy: 0.0408 - val_loss: 21.1056\n",
      "Epoch 52/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9423 - loss: 0.1697 - val_accuracy: 0.0408 - val_loss: 20.9294\n",
      "Epoch 53/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9464 - loss: 0.1547 - val_accuracy: 0.0408 - val_loss: 20.7615\n",
      "Epoch 54/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9419 - loss: 0.1744 - val_accuracy: 0.0561 - val_loss: 20.7931\n",
      "Epoch 55/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9421 - loss: 0.1742 - val_accuracy: 0.0408 - val_loss: 21.0174\n",
      "Epoch 56/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9423 - loss: 0.1552 - val_accuracy: 0.0561 - val_loss: 20.9437\n",
      "Epoch 57/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9321 - loss: 0.2026 - val_accuracy: 0.0459 - val_loss: 20.8412\n",
      "Epoch 58/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9326 - loss: 0.1796 - val_accuracy: 0.0357 - val_loss: 21.2549\n",
      "Epoch 59/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9509 - loss: 0.1490 - val_accuracy: 0.0459 - val_loss: 20.7993\n",
      "Epoch 60/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9435 - loss: 0.1599 - val_accuracy: 0.0357 - val_loss: 20.9980\n",
      "Epoch 61/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9487 - loss: 0.1675 - val_accuracy: 0.0459 - val_loss: 20.6493\n",
      "Epoch 62/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9404 - loss: 0.1702 - val_accuracy: 0.0357 - val_loss: 20.4662\n",
      "Epoch 63/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9499 - loss: 0.1509 - val_accuracy: 0.0357 - val_loss: 20.5266\n",
      "Epoch 64/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9451 - loss: 0.1681 - val_accuracy: 0.0408 - val_loss: 20.4550\n",
      "Epoch 65/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9470 - loss: 0.1661 - val_accuracy: 0.0357 - val_loss: 20.7604\n",
      "Epoch 66/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9319 - loss: 0.1976 - val_accuracy: 0.0459 - val_loss: 20.6444\n",
      "Epoch 67/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9418 - loss: 0.1668 - val_accuracy: 0.0357 - val_loss: 20.7420\n",
      "Epoch 68/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9468 - loss: 0.1610 - val_accuracy: 0.0459 - val_loss: 20.4795\n",
      "Epoch 69/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9492 - loss: 0.1501 - val_accuracy: 0.0459 - val_loss: 20.3711\n",
      "Epoch 70/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9402 - loss: 0.1703 - val_accuracy: 0.0408 - val_loss: 20.4766\n",
      "Epoch 71/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9443 - loss: 0.1555 - val_accuracy: 0.0408 - val_loss: 20.3323\n",
      "Epoch 72/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9554 - loss: 0.1337 - val_accuracy: 0.0510 - val_loss: 20.3437\n",
      "Epoch 73/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9459 - loss: 0.1543 - val_accuracy: 0.0408 - val_loss: 20.5052\n",
      "Epoch 74/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9380 - loss: 0.1621 - val_accuracy: 0.0561 - val_loss: 19.7516\n",
      "Epoch 75/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9393 - loss: 0.1610 - val_accuracy: 0.0408 - val_loss: 20.0274\n",
      "Epoch 76/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9419 - loss: 0.1733 - val_accuracy: 0.0459 - val_loss: 19.8591\n",
      "Epoch 77/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9423 - loss: 0.1590 - val_accuracy: 0.0561 - val_loss: 19.9442\n",
      "Epoch 78/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9430 - loss: 0.1523 - val_accuracy: 0.0459 - val_loss: 19.9945\n",
      "Epoch 79/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9395 - loss: 0.1708 - val_accuracy: 0.0408 - val_loss: 19.8109\n",
      "Epoch 80/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9395 - loss: 0.1678 - val_accuracy: 0.0459 - val_loss: 19.6343\n",
      "Epoch 81/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9351 - loss: 0.1771 - val_accuracy: 0.0408 - val_loss: 19.6447\n",
      "Epoch 82/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9400 - loss: 0.1611 - val_accuracy: 0.0510 - val_loss: 19.7468\n",
      "Epoch 83/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9480 - loss: 0.1568 - val_accuracy: 0.0459 - val_loss: 19.5001\n",
      "Epoch 84/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9525 - loss: 0.1501 - val_accuracy: 0.0459 - val_loss: 19.6926\n",
      "Epoch 85/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9463 - loss: 0.1600 - val_accuracy: 0.0561 - val_loss: 19.1220\n",
      "Epoch 86/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9493 - loss: 0.1578 - val_accuracy: 0.0459 - val_loss: 19.2794\n",
      "Epoch 87/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9304 - loss: 0.1864 - val_accuracy: 0.0561 - val_loss: 18.9765\n",
      "Epoch 88/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9449 - loss: 0.1708 - val_accuracy: 0.0459 - val_loss: 19.1287\n",
      "Epoch 89/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9544 - loss: 0.1495 - val_accuracy: 0.0408 - val_loss: 19.3414\n",
      "Epoch 90/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9381 - loss: 0.1711 - val_accuracy: 0.0408 - val_loss: 19.3994\n",
      "Epoch 91/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9378 - loss: 0.1587 - val_accuracy: 0.0408 - val_loss: 19.1187\n",
      "Epoch 92/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9368 - loss: 0.1724 - val_accuracy: 0.0459 - val_loss: 19.1387\n",
      "Epoch 93/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9461 - loss: 0.1509 - val_accuracy: 0.0408 - val_loss: 19.1317\n",
      "Epoch 94/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9459 - loss: 0.1377 - val_accuracy: 0.0510 - val_loss: 18.8171\n",
      "Epoch 95/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9342 - loss: 0.1797 - val_accuracy: 0.0459 - val_loss: 18.9606\n",
      "Epoch 96/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9357 - loss: 0.1829 - val_accuracy: 0.0459 - val_loss: 19.0732\n",
      "Epoch 97/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9430 - loss: 0.1512 - val_accuracy: 0.0408 - val_loss: 18.5339\n",
      "Epoch 98/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9512 - loss: 0.1498 - val_accuracy: 0.0408 - val_loss: 18.5191\n",
      "Epoch 99/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9376 - loss: 0.1636 - val_accuracy: 0.0408 - val_loss: 18.8445\n",
      "Epoch 100/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9433 - loss: 0.1603 - val_accuracy: 0.0510 - val_loss: 18.6605\n",
      "Epoch 101/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9452 - loss: 0.1530 - val_accuracy: 0.0510 - val_loss: 18.3842\n",
      "Epoch 102/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9424 - loss: 0.1631 - val_accuracy: 0.0408 - val_loss: 18.5725\n",
      "Epoch 103/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9561 - loss: 0.1397 - val_accuracy: 0.0408 - val_loss: 18.6254\n",
      "Epoch 104/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9477 - loss: 0.1543 - val_accuracy: 0.0408 - val_loss: 18.6635\n",
      "Epoch 105/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9463 - loss: 0.1439 - val_accuracy: 0.0408 - val_loss: 18.9266\n",
      "Epoch 106/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9446 - loss: 0.1599 - val_accuracy: 0.0408 - val_loss: 18.1166\n",
      "Epoch 107/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9430 - loss: 0.1595 - val_accuracy: 0.0510 - val_loss: 18.3019\n",
      "Epoch 108/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9379 - loss: 0.1529 - val_accuracy: 0.0408 - val_loss: 18.1584\n",
      "Epoch 109/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9430 - loss: 0.1402 - val_accuracy: 0.0510 - val_loss: 18.2189\n",
      "Epoch 110/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9458 - loss: 0.1621 - val_accuracy: 0.0408 - val_loss: 18.1558\n",
      "Epoch 111/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9524 - loss: 0.1373 - val_accuracy: 0.0459 - val_loss: 18.1177\n",
      "Epoch 112/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9360 - loss: 0.1685 - val_accuracy: 0.0357 - val_loss: 18.1989\n",
      "Epoch 113/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9431 - loss: 0.1642 - val_accuracy: 0.0408 - val_loss: 18.1044\n",
      "Epoch 114/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9430 - loss: 0.1587 - val_accuracy: 0.0408 - val_loss: 18.2453\n",
      "Epoch 115/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9461 - loss: 0.1369 - val_accuracy: 0.0408 - val_loss: 18.1523\n",
      "Epoch 116/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9389 - loss: 0.1844 - val_accuracy: 0.0357 - val_loss: 18.0822\n",
      "Epoch 117/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9379 - loss: 0.1755 - val_accuracy: 0.0408 - val_loss: 17.9437\n",
      "Epoch 118/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9460 - loss: 0.1525 - val_accuracy: 0.0408 - val_loss: 17.8327\n",
      "Epoch 119/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9433 - loss: 0.1567 - val_accuracy: 0.0357 - val_loss: 18.1116\n",
      "Epoch 120/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9402 - loss: 0.1701 - val_accuracy: 0.0408 - val_loss: 17.8636\n",
      "Epoch 121/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.1440 - val_accuracy: 0.0459 - val_loss: 17.7376\n",
      "Epoch 122/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9435 - loss: 0.1561 - val_accuracy: 0.0357 - val_loss: 17.6236\n",
      "Epoch 123/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9380 - loss: 0.1651 - val_accuracy: 0.0357 - val_loss: 17.4980\n",
      "Epoch 124/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9422 - loss: 0.1632 - val_accuracy: 0.0357 - val_loss: 17.5021\n",
      "Epoch 125/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9483 - loss: 0.1430 - val_accuracy: 0.0357 - val_loss: 17.6319\n",
      "Epoch 126/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9505 - loss: 0.1373 - val_accuracy: 0.0357 - val_loss: 17.6828\n",
      "Epoch 127/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9497 - loss: 0.1337 - val_accuracy: 0.0357 - val_loss: 17.5364\n",
      "Epoch 128/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9518 - loss: 0.1472 - val_accuracy: 0.0357 - val_loss: 17.5565\n",
      "Epoch 129/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9475 - loss: 0.1446 - val_accuracy: 0.0357 - val_loss: 17.4117\n",
      "Epoch 130/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9512 - loss: 0.1452 - val_accuracy: 0.0357 - val_loss: 17.2920\n",
      "Epoch 131/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9383 - loss: 0.1856 - val_accuracy: 0.0357 - val_loss: 17.3034\n",
      "Epoch 132/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9432 - loss: 0.1551 - val_accuracy: 0.0357 - val_loss: 17.3594\n",
      "Epoch 133/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9508 - loss: 0.1397 - val_accuracy: 0.0357 - val_loss: 17.4055\n",
      "Epoch 134/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9399 - loss: 0.1497 - val_accuracy: 0.0357 - val_loss: 17.1217\n",
      "Epoch 135/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9383 - loss: 0.1731 - val_accuracy: 0.0357 - val_loss: 17.2540\n",
      "Epoch 136/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9520 - loss: 0.1211 - val_accuracy: 0.0357 - val_loss: 17.0822\n",
      "Epoch 137/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9459 - loss: 0.1504 - val_accuracy: 0.0357 - val_loss: 17.1883\n",
      "Epoch 138/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9445 - loss: 0.1547 - val_accuracy: 0.0357 - val_loss: 17.1442\n",
      "Epoch 139/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9535 - loss: 0.1398 - val_accuracy: 0.0357 - val_loss: 17.1659\n",
      "Epoch 140/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9454 - loss: 0.1462 - val_accuracy: 0.0357 - val_loss: 17.2125\n",
      "Epoch 141/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9509 - loss: 0.1457 - val_accuracy: 0.0357 - val_loss: 17.4785\n",
      "Epoch 142/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9527 - loss: 0.1311 - val_accuracy: 0.0357 - val_loss: 17.4265\n",
      "Epoch 143/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9392 - loss: 0.1645 - val_accuracy: 0.0357 - val_loss: 17.4136\n",
      "Epoch 144/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9482 - loss: 0.1522 - val_accuracy: 0.0357 - val_loss: 17.3127\n",
      "Epoch 145/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9437 - loss: 0.1502 - val_accuracy: 0.0357 - val_loss: 17.2892\n",
      "Epoch 146/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9486 - loss: 0.1468 - val_accuracy: 0.0357 - val_loss: 17.3108\n",
      "Epoch 147/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9528 - loss: 0.1252 - val_accuracy: 0.0357 - val_loss: 17.2341\n",
      "Epoch 148/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9448 - loss: 0.1564 - val_accuracy: 0.0357 - val_loss: 17.1631\n",
      "Epoch 149/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9543 - loss: 0.1254 - val_accuracy: 0.0357 - val_loss: 17.0907\n",
      "Epoch 150/150\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9568 - loss: 0.1358 - val_accuracy: 0.0357 - val_loss: 17.1905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2c0a9a5e000>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded_data, labels, epochs=150, verbose=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "70b508d7-94cc-4af1-a472-f1cc9202c8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The argument passed to the chatbot function is the user query. The result returned by the function is the chatbot response.\n",
    "\n",
    "def chatbot(input_sentence):\n",
    "    if not input_sentence.strip():\n",
    "        return 'Sorry. I did not understand. Could you please rephrase?'\n",
    "        \n",
    "    processed_text = preprocess(input_sentence, remove_stopwords=True)  #function preprocess defined previously\n",
    "    \n",
    "    txt = tokens.texts_to_sequences(processed_text.split())\n",
    "    coded_txt = [x for y in txt for x in y]\n",
    "    padded_data = pad_sequences([coded_txt], maxlen=max_length, padding='post', value=0)  # processed text converted into padded sequence\n",
    "    \n",
    "    out = (model.predict(padded_data)).argmax()\n",
    "\n",
    "    #adding a confidence threshold of 40%\n",
    "    \n",
    "    if out>0.4:\n",
    "        label_out = label_en.inverse_transform([out]) #convert the predicted label into the corresponding tag\n",
    "        label_out = ''.join(label_out)\n",
    "        response = uni_data_out[uni_data_out['tags']==label_out]['responses']  #select list of responses corresponding to the tag\n",
    "        response = random.choice(list(response)) #random selection of one of the respones for the given tag\n",
    "        return response\n",
    "        \n",
    "    else:\n",
    "        return 'Sorry. Could not understand. Please rephrase.'\n",
    "\n",
    "    if response.empty: \n",
    "        return \"Sorry, I couldn't find a suitable response.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0b5a2502-bec8-462e-b069-0e318b804b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  fees first for year\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step\n",
      "Chatbot:  For Fee detail visit <a target=\"_blank\" href=\"LINK\"> here</a>\n"
     ]
    }
   ],
   "source": [
    "input_no = int(input())  #maximum integer input 411\n",
    "\n",
    "#user input\n",
    "print('User: ', uni_data_in['user_input'][input_no])\n",
    "\n",
    "# chatbot response\n",
    "print('Chatbot: ', chatbot(uni_data_in['user_input'][input_no]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "3a56ccfe-ae30-4a98-b9a9-36b64b9d3c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'For hostel detail visit <a target=\"_blank\" href=\"ADD YOUR HOSTEL DETAIL PDF LINK OR ANY INFORMATION LINK OR ADD YOU OWN ANSWERS\"> here</a>'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot('what are the hostel facilities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897273e3-a6ac-4155-aba0-fa55b38b8185",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
